{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "661bad04",
      "metadata": {
        "id": "661bad04"
      },
      "source": [
        "## Examples: Implementing an ensemble method using `scikit-learn`\n",
        "Let's implement a basic ensemble method using the `scikit-learn` library. We'll use the dataset provided to predict the `BiodiversityHealthIndex` using both a single model and an ensemble method for comparison. For the ensemble, we'll use a `RandomForestRegressor`, a popular bagging method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "62341cd8",
      "metadata": {
        "id": "62341cd8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/SDG_15_Life_on_Land_Dataset.csv')\n",
        "\n",
        "# Define features and target\n",
        "X = data.drop('BiodiversityHealthIndex', axis=1)\n",
        "y = data['BiodiversityHealthIndex']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d892fee",
      "metadata": {
        "id": "7d892fee"
      },
      "source": [
        " Building individual models\n",
        "\n",
        "Let's first build a simple decision tree regressor as our weak learner for comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6477dc99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6477dc99",
        "outputId": "ef12427f-a64b-404a-f709-cbf1d8fd1d76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree MSE: 0.08696874034772016\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Initialise and train the decision tree\n",
        "tree_model = DecisionTreeRegressor(random_state=42, max_depth=3)\n",
        "tree_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "tree_predictions = tree_model.predict(X_test)\n",
        "tree_mse = mean_squared_error(y_test, tree_predictions)\n",
        "print(f\"Decision Tree MSE: {tree_mse}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9956efe",
      "metadata": {
        "tags": [],
        "id": "e9956efe"
      },
      "source": [
        " Building an ensemble model\n",
        "\n",
        "Now, let's use the `RandomForestRegressor` as our ensemble method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "466cb7fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "466cb7fd",
        "outputId": "ce9e665b-1c60-47e1-d7f5-34b7b22b2442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest MSE: 0.0858280816891359\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Initialise and train the random forest\n",
        "forest_model = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=3)\n",
        "forest_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "forest_predictions = forest_model.predict(X_test)\n",
        "forest_mse = mean_squared_error(y_test, forest_predictions)\n",
        "print(f\"Random Forest MSE: {forest_mse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff6c543f",
      "metadata": {
        "id": "ff6c543f"
      },
      "source": [
        "## Conclusion\n",
        "By comparing the mean squared error (MSE) of the decision tree model with that of the random forest, we can observe the impact of using ensemble methods. Note that we used a `max_depth=3` parameter in both the decision tree and random forest models, to ensure we're seeing the impact of using ensembles. Typically, the random forest (an ensemble method) should outperform the single decision tree due to its ability to reduce overfitting and variance in predictions. Limiting the max_depth parameter prevents overfitting the data, which could lead to individual trees being rather complex and elaborate."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}